#!/usr/bin/env python3
"""
æ•°æ®é›†é‡‡æ ·è„šæœ¬
å¯¹æ¯ä¸ªç”¨æˆ·éšæœºä¿ç•™æœ€å¤š N ä¸ªæ ·æœ¬ï¼Œç”Ÿæˆæ–°çš„æ•°æ®é›†æ–‡ä»¶

ç”¨æ³•:
    python sample_dataset.py <input_json> <output_json> --max_samples <N> --seed <seed>
    
ç¤ºä¾‹:
    python sample_dataset.py /path/to/train.json /path/to/train_3.json --max_samples 3 --seed 42
"""

import json
import random
import argparse
from collections import defaultdict
from pathlib import Path


def sample_dataset(input_path, output_path, max_samples_per_user=3, seed=42, user_id_field='user_hash'):
    """
    å¯¹æ•°æ®é›†è¿›è¡Œé‡‡æ ·ï¼Œæ¯ä¸ªç”¨æˆ·æœ€å¤šä¿ç•™ max_samples_per_user ä¸ªæ ·æœ¬
    
    Args:
        input_path: è¾“å…¥JSONæ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„
        max_samples_per_user: æ¯ä¸ªç”¨æˆ·æœ€å¤šä¿ç•™çš„æ ·æœ¬æ•°
        seed: éšæœºç§å­
        user_id_field: ç”¨æˆ·IDå­—æ®µåï¼ˆå¯ä»¥æ˜¯ 'user_hash', 'user_id', 'userId' ç­‰ï¼‰
    """
    random.seed(seed)
    
    print(f"=" * 80)
    print(f"æ•°æ®é›†é‡‡æ ·å·¥å…·")
    print(f"=" * 80)
    print(f"è¾“å…¥æ–‡ä»¶: {input_path}")
    print(f"è¾“å‡ºæ–‡ä»¶: {output_path}")
    print(f"æ¯ç”¨æˆ·æœ€å¤šæ ·æœ¬æ•°: {max_samples_per_user}")
    print(f"éšæœºç§å­: {seed}")
    print(f"ç”¨æˆ·IDå­—æ®µ: {user_id_field}")
    print()
    
    # è¯»å–æ•°æ®é›†
    print("ğŸ“– è¯»å–æ•°æ®é›†...")
    with open(input_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    original_count = len(data)
    print(f"âœ… åŸå§‹æ ·æœ¬æ•°: {original_count}")
    
    # è‡ªåŠ¨æ£€æµ‹ç”¨æˆ·IDå­—æ®µ
    if data:
        first_sample = data[0]
        possible_fields = ['user_hash', 'user_id', 'userId', 'target_user_id', 'author']
        detected_field = None
        for field in possible_fields:
            if field in first_sample:
                detected_field = field
                break
        
        if detected_field and detected_field != user_id_field:
            print(f"âš ï¸  æ£€æµ‹åˆ°ç”¨æˆ·IDå­—æ®µ: {detected_field} (è¦†ç›–é»˜è®¤å€¼ {user_id_field})")
            user_id_field = detected_field
    
    # æŒ‰ç”¨æˆ·åˆ†ç»„
    print(f"ğŸ“Š æŒ‰ç”¨æˆ·åˆ†ç»„ (ä½¿ç”¨å­—æ®µ: {user_id_field})...")
    user_samples = defaultdict(list)
    
    for sample in data:
        user_id = sample.get(user_id_field)
        if user_id is None:
            print(f"âš ï¸  è­¦å‘Š: æ ·æœ¬ç¼ºå°‘ {user_id_field} å­—æ®µï¼Œè·³è¿‡")
            continue
        user_samples[user_id].append(sample)
    
    num_users = len(user_samples)
    print(f"âœ… å”¯ä¸€ç”¨æˆ·æ•°: {num_users}")
    print(f"âœ… å¹³å‡æ¯ç”¨æˆ·æ ·æœ¬æ•°: {original_count / num_users:.2f}")
    
    # ç»Ÿè®¡æ ·æœ¬åˆ†å¸ƒ
    from collections import Counter
    sample_counts = [len(samples) for samples in user_samples.values()]
    count_dist = Counter(sample_counts)
    print(f"\næ ·æœ¬æ•°åˆ†å¸ƒ (å‰10ä¸ª):")
    for count, num_users_with_count in sorted(count_dist.items())[:10]:
        print(f"  {count:3d} ä¸ªæ ·æœ¬: {num_users_with_count:5d} ä¸ªç”¨æˆ·")
    
    if len(count_dist) > 10:
        print(f"  ... (å…± {len(count_dist)} ç§ä¸åŒçš„æ ·æœ¬æ•°)")
    
    # é‡‡æ ·
    print(f"\nğŸ² å¼€å§‹é‡‡æ · (æ¯ç”¨æˆ·æœ€å¤š {max_samples_per_user} ä¸ªæ ·æœ¬)...")
    sampled_data = []
    affected_users = 0
    removed_samples = 0
    
    for user_id, samples in user_samples.items():
        original_sample_count = len(samples)
        
        if original_sample_count > max_samples_per_user:
            # éœ€è¦é‡‡æ ·
            sampled = random.sample(samples, max_samples_per_user)
            affected_users += 1
            removed_samples += (original_sample_count - max_samples_per_user)
        else:
            # ä¿ç•™å…¨éƒ¨
            sampled = samples
        
        sampled_data.extend(sampled)
    
    # æ‰“ä¹±é¡ºåº
    random.shuffle(sampled_data)
    
    new_count = len(sampled_data)
    print(f"âœ… é‡‡æ ·å®Œæˆ")
    print(f"   - æ–°æ ·æœ¬æ•°: {new_count}")
    print(f"   - ç§»é™¤æ ·æœ¬æ•°: {removed_samples} ({removed_samples/original_count*100:.2f}%)")
    print(f"   - å—å½±å“ç”¨æˆ·æ•°: {affected_users} ({affected_users/num_users*100:.2f}%)")
    print(f"   - ä¿ç•™æ¯”ä¾‹: {new_count/original_count*100:.2f}%")
    
    # ä¿å­˜
    print(f"\nğŸ’¾ ä¿å­˜åˆ°: {output_path}")
    output_path_obj = Path(output_path)
    output_path_obj.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(sampled_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… å®Œæˆï¼")
    print(f"=" * 80)
    
    return {
        'original_count': original_count,
        'new_count': new_count,
        'num_users': num_users,
        'affected_users': affected_users,
        'removed_samples': removed_samples,
    }


def main():
    parser = argparse.ArgumentParser(
        description='å¯¹æ•°æ®é›†è¿›è¡Œé‡‡æ ·ï¼Œæ¯ä¸ªç”¨æˆ·æœ€å¤šä¿ç•™Nä¸ªæ ·æœ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # Chameleons æ•°æ®é›†ï¼Œæ¯ç”¨æˆ·æœ€å¤š3ä¸ªæ ·æœ¬
  python sample_dataset.py \\
      /mnt/parallel/GIDigitalTwinBench/RealSelf/Chameleons/train.json \\
      /mnt/parallel/GIDigitalTwinBench/RealSelf/Chameleons/train_3.json \\
      --max_samples 3 --seed 42
  
  # REALTALK æ•°æ®é›†ï¼Œæ¯ç”¨æˆ·æœ€å¤š5ä¸ªæ ·æœ¬
  python sample_dataset.py \\
      /mnt/parallel/GIDigitalTwinBench/RealSelf/REALTALK/train.json \\
      /mnt/parallel/GIDigitalTwinBench/RealSelf/REALTALK/train_5.json \\
      --max_samples 5 --seed 42
        """
    )
    
    parser.add_argument('input', type=str, help='è¾“å…¥JSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('output', type=str, help='è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--max_samples', type=int, default=3,
                        help='æ¯ä¸ªç”¨æˆ·æœ€å¤šä¿ç•™çš„æ ·æœ¬æ•° (é»˜è®¤: 3)')
    parser.add_argument('--seed', type=int, default=42,
                        help='éšæœºç§å­ (é»˜è®¤: 42)')
    parser.add_argument('--user_id_field', type=str, default='user_hash',
                        help='ç”¨æˆ·IDå­—æ®µå (é»˜è®¤: user_hashï¼Œä¼šè‡ªåŠ¨æ£€æµ‹)')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(args.input).exists():
        print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return 1
    
    # æ‰§è¡Œé‡‡æ ·
    sample_dataset(
        input_path=args.input,
        output_path=args.output,
        max_samples_per_user=args.max_samples,
        seed=args.seed,
        user_id_field=args.user_id_field
    )
    
    return 0


if __name__ == '__main__':
    exit(main())
