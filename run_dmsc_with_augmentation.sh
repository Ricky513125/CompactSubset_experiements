#!/bin/bash
# DMSC å½±è¯„æ•°æ®é›†è®­ç»ƒè„šæœ¬
# æ³¨æ„ï¼šDMSC æ•°æ®åŠ è½½å™¨å·²è‡ªåŠ¨æŒ‰æ—¶åºç”Ÿæˆè®­ç»ƒæ ·æœ¬ï¼Œæ— éœ€é¢å¤–æ‰©å……
# ä½¿ç”¨æ–¹æ³•: bash run_dmsc_with_augmentation.sh

set -e

# é…ç½®å‚æ•°
CONFIG="config_DMSC.json"
DEEPSPEED="ds_config_zero2.json"
ABLATION="history_only"
OUTPUT_DIR="outputs/DMSC_history_augmented_0211"
WANDB_PROJECT="Qwen3-DMSC-Augmented"
WANDB_RUN="history_aug_0211"
NUM_GPUS=8
MASTER_PORT=29500

echo "========================================"
echo "DMSC å½±è¯„æ•°æ®è®­ç»ƒ"
echo "========================================"
echo "é…ç½®æ–‡ä»¶: $CONFIG"
echo "DeepSpeedé…ç½®: $DEEPSPEED"
echo "æ¶ˆèé…ç½®: $ABLATION"
echo "è¾“å‡ºç›®å½•: $OUTPUT_DIR"
echo "GPUæ•°é‡: $NUM_GPUS"
echo "========================================"
echo ""
echo "ğŸ“ æ³¨æ„: DMSC å½±è¯„æ•°æ®åŠ è½½å™¨å·²è‡ªåŠ¨æŒ‰æ—¶åºç”Ÿæˆè®­ç»ƒæ ·æœ¬"
echo "  æ¯æ¡å½±è¯„ â†’ 1ä¸ªè®­ç»ƒæ ·æœ¬ï¼ˆåŒ…å«ä¹‹å‰æ‰€æœ‰å½±è¯„ä½œä¸ºå†å²ï¼‰"
echo "  æ— éœ€é¢å¤–çš„æ—¶åºæ‰©å……"
echo "========================================"
echo ""

# è®¾ç½®ç¯å¢ƒå˜é‡
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
export TOKENIZERS_PARALLELISM=false

# å¯åŠ¨è®­ç»ƒ
torchrun \
    --nproc_per_node=$NUM_GPUS \
    --master_port=$MASTER_PORT \
    train_distributed_MovieReview.py \
    --config $CONFIG \
    --deepspeed $DEEPSPEED \
    --ablation_config $ABLATION \
    --output_dir $OUTPUT_DIR \
    --max_epochs 50 \
    --early_stopping_patience 5 \
    --early_stopping_threshold 0.001 \
    --val_ratio 0.1 \
    --wandb_project $WANDB_PROJECT \
    --wandb_run_name $WANDB_RUN \
    --prompt_style simple

echo ""
echo "========================================"
echo "è®­ç»ƒå®Œæˆï¼"
echo "æ¨¡å‹ä¿å­˜åœ¨: $OUTPUT_DIR"
echo "========================================"
