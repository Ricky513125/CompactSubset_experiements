#!/usr/bin/env python3
"""
LoRA å¾®è°ƒé…ç½®ç”Ÿæˆå™¨
ä¸º Chameleons æ•°æ®é›†ç”Ÿæˆ LoRA è®­ç»ƒé…ç½®
"""

import json
from pathlib import Path

# åŸºç¡€é…ç½®
base_config = {
    "model": {
        "name": "Qwen3-30B-A3B-Instruct-2507",
        "path": "/mnt/parallel/models/Qwen3-30B-A3B-Instruct-2507",
        "hf_model_name": "Qwen/Qwen3-30B-A3B-Instruct-2507",
        "checkpoint_dir": "/mnt/parallel/checkpoints",
        
        # LoRA é…ç½®
        "use_lora": True,
        "lora_config": {
            "r": 64,                    # LoRA rank (32-128)
            "lora_alpha": 128,          # LoRA alpha (é€šå¸¸ = 2*r)
            "lora_dropout": 0.05,       # Dropout
            "target_modules": [         # è¦åº”ç”¨ LoRA çš„æ¨¡å—
                "q_proj",
                "k_proj", 
                "v_proj",
                "o_proj",
                "gate_proj",
                "up_proj",
                "down_proj"
            ],
            "bias": "none",
            "task_type": "CAUSAL_LM"
        }
    },
    "data": {
        "train_path": "sampled_data/Chameleons/train_di3.json"
    },
    "training": {
        "batch_size": 2,              # LoRA å¯ä»¥ç”¨æ›´å¤§çš„ batch size
        "eval_batch_size": 2,
        "gradient_accumulation_steps": 4,  # æœ‰æ•ˆ batch = 2*4*8 = 64
        "learning_rate": 2e-4,        # LoRA é€šå¸¸ç”¨æ›´é«˜çš„å­¦ä¹ ç‡
        "weight_decay": 0.01,
        "warmup_steps": 100,
        "max_length": 1024,
        "max_context_turns": 15,
        "logging_steps": 10,
        "save_steps": 200,            # æ›´é¢‘ç¹ä¿å­˜
        "save_total_limit": 5
    },
    "ablation_configs": {
        "profile_and_history_and_context": {
            "use_profile": True,
            "use_history": True,
            "use_context": True,
            "name": "profile_and_history_and_context"
        },
        "profile_and_history": {
            "use_profile": True,
            "use_history": True,
            "use_context": False,
            "name": "profile_and_history"
        },
        "profile_and_context": {
            "use_profile": True,
            "use_history": False,
            "use_context": True,
            "name": "profile_and_context"
        },
        "history_and_context": {
            "use_profile": False,
            "use_history": True,
            "use_context": True,
            "name": "history_and_context"
        },
        "profile_only": {
            "use_profile": True,
            "use_history": False,
            "use_context": False,
            "name": "profile_only"
        },
        "history_only": {
            "use_profile": False,
            "use_history": True,
            "use_context": False,
            "name": "history_only"
        },
        "context_only": {
            "use_profile": False,
            "use_history": False,
            "use_context": True,
            "name": "context_only"
        }
    }
}

# ä¿å­˜é…ç½®
output_path = Path("config_Chameleons_30B_lora_di3.json")
with open(output_path, 'w', encoding='utf-8') as f:
    json.dump(base_config, f, indent=2, ensure_ascii=False)

print(f"âœ… LoRA é…ç½®å·²ä¿å­˜åˆ°: {output_path}")
print("\né…ç½®è¦ç‚¹:")
print(f"  - LoRA rank: {base_config['model']['lora_config']['r']}")
print(f"  - Target modules: {len(base_config['model']['lora_config']['target_modules'])} ä¸ª")
print(f"  - Batch size: {base_config['training']['batch_size']} (æœ‰æ•ˆ batch size = {base_config['training']['batch_size'] * base_config['training']['gradient_accumulation_steps'] * 8})")
print(f"  - Learning rate: {base_config['training']['learning_rate']}")
print(f"  - æ•°æ®é›†: {base_config['data']['train_path']}")
print("\né¢„æœŸæ”¹è¿›:")
print("  âš¡ è®­ç»ƒé€Ÿåº¦: 3-5x åŠ é€Ÿ")
print("  ğŸ’¾ æ˜¾å­˜å ç”¨: 50-70% å‡å°‘")
print("  â±ï¸  è®­ç»ƒæ—¶é—´: ä» 12.5 å¤© â†’ 2-3 å¤©")
