#!/usr/bin/env python3
"""
DMSC æ•°æ®é›†é‡‡æ ·è„šæœ¬
å¯¹æ¯ä¸ªç”¨æˆ·æŒ‰æ—¶é—´æˆ³æ’åºï¼Œä¿ç•™å X% çš„è¯„è®º

ç”¨æ³•:
    python sample_dataset_DMSC.py <input_json> <output_json> --keep_ratio <0.0-1.0> [--user_id_field <field>]
    
ç¤ºä¾‹:
    # ä¿ç•™æ¯ä¸ªç”¨æˆ·çš„å50%è¯„è®º
    python sample_dataset_DMSC.py /path/to/train.json /path/to/train_50pct.json --keep_ratio 0.5
    
    # ä¿ç•™æ¯ä¸ªç”¨æˆ·çš„å30%è¯„è®º
    python sample_dataset_DMSC.py /path/to/train.json /path/to/train_30pct.json --keep_ratio 0.3
"""

import json
import argparse
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
from collections import defaultdict


def parse_timestamp(timestamp_str: str) -> datetime:
    """
    è§£ææ—¶é—´æˆ³å­—ç¬¦ä¸²
    
    æ”¯æŒæ ¼å¼:
    - "2012-12-24"
    - "2012-12-24 10:30:00"
    - "2012-12-24T10:30:00"
    """
    timestamp_str = timestamp_str.strip()
    
    # å°è¯•ä¸åŒçš„æ—¥æœŸæ ¼å¼
    formats = [
        "%Y-%m-%d",
        "%Y-%m-%d %H:%M:%S",
        "%Y-%m-%dT%H:%M:%S",
        "%Y/%m/%d",
        "%Y/%m/%d %H:%M:%S",
    ]
    
    for fmt in formats:
        try:
            return datetime.strptime(timestamp_str, fmt)
        except ValueError:
            continue
    
    # å¦‚æœéƒ½å¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªå¾ˆæ—§çš„æ—¥æœŸï¼ˆè¿™æ ·ä¼šæ’åœ¨å‰é¢ï¼‰
    print(f"âš ï¸  è­¦å‘Š: æ— æ³•è§£ææ—¶é—´æˆ³ '{timestamp_str}'ï¼Œä½¿ç”¨é»˜è®¤å€¼ 1970-01-01")
    return datetime(1970, 1, 1)


def get_user_id(user_data: Dict[str, Any], user_id_field: str = 'name') -> Optional[str]:
    """
    ä»ç”¨æˆ·æ•°æ®ä¸­æå–ç”¨æˆ·ID
    
    Args:
        user_data: ç”¨æˆ·æ•°æ®å¯¹è±¡ï¼ˆåŒ…å« user å’Œ task å­—æ®µï¼‰
        user_id_field: ç”¨æˆ·IDå­—æ®µåï¼ˆé»˜è®¤ä» user.profile.name è·å–ï¼‰
    
    Returns:
        ç”¨æˆ·IDå­—ç¬¦ä¸²ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™è¿”å› None
    """
    if user_id_field == 'name':
        # é»˜è®¤ä» user.profile.name è·å–
        profile = user_data.get('user', {}).get('profile', {})
        return profile.get('name')
    else:
        # å°è¯•ä»ä¸åŒä½ç½®è·å–
        if user_id_field in user_data:
            return user_data[user_id_field]
        if 'user' in user_data and user_id_field in user_data['user']:
            return user_data['user'][user_id_field]
        if 'user' in user_data and 'profile' in user_data['user']:
            return user_data['user']['profile'].get(user_id_field)
    return None


def collect_all_reviews(user_data: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    æ”¶é›†ç”¨æˆ·çš„æ‰€æœ‰è¯„è®ºï¼ˆè·¨æ‰€æœ‰ collectionï¼‰
    
    Args:
        user_data: ç”¨æˆ·æ•°æ®å¯¹è±¡
    
    Returns:
        æ‰€æœ‰è¯„è®ºçš„åˆ—è¡¨ï¼Œæ¯ä¸ªè¯„è®ºåŒ…å«åŸå§‹æ•°æ®å’Œå…ƒæ•°æ®
    """
    all_reviews = []
    
    task = user_data.get('task', {})
    collections = task.get('task_behavior_collections', [])
    
    for collection_idx, collection in enumerate(collections):
        data_items = collection.get('data', [])
        
        for data_idx, data_item in enumerate(data_items):
            # ä¸ºæ¯ä¸ªè¯„è®ºæ·»åŠ å…ƒæ•°æ®ï¼Œä»¥ä¾¿åç»­é‡æ–°åˆ†é…
            review_with_meta = {
                'data_item': data_item,
                'collection_idx': collection_idx,
                'data_idx': data_idx,
            }
            all_reviews.append(review_with_meta)
    
    return all_reviews


def sample_dmsc_dataset(
    input_path: str,
    output_path: str,
    keep_ratio: float = 0.5,
    user_id_field: str = 'name'
):
    """
    å¯¹DMSCæ•°æ®é›†è¿›è¡Œé‡‡æ ·ï¼Œæ¯ä¸ªç”¨æˆ·ä¿ç•™å keep_ratio æ¯”ä¾‹çš„è¯„è®º
    
    Args:
        input_path: è¾“å…¥JSONæ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„
        keep_ratio: ä¿ç•™æ¯”ä¾‹ï¼ˆ0.0-1.0ï¼‰ï¼Œä¾‹å¦‚ 0.5 è¡¨ç¤ºä¿ç•™å50%
        user_id_field: ç”¨æˆ·IDå­—æ®µåï¼ˆé»˜è®¤ä» user.profile.name è·å–ï¼‰
    """
    print("=" * 80)
    print("DMSC æ•°æ®é›†é‡‡æ ·å·¥å…·ï¼ˆæŒ‰æ—¶é—´æˆ³ä¿ç•™åX%ï¼‰")
    print("=" * 80)
    print(f"è¾“å…¥æ–‡ä»¶: {input_path}")
    print(f"è¾“å‡ºæ–‡ä»¶: {output_path}")
    print(f"ä¿ç•™æ¯”ä¾‹: {keep_ratio * 100:.1f}% (å{keep_ratio * 100:.1f}%)")
    print(f"ç”¨æˆ·IDå­—æ®µ: {user_id_field}")
    print()
    
    if not (0.0 < keep_ratio <= 1.0):
        print(f"âŒ é”™è¯¯: keep_ratio å¿…é¡»åœ¨ (0.0, 1.0] èŒƒå›´å†…ï¼Œå½“å‰å€¼: {keep_ratio}")
        return None
    
    # è¯»å–æ•°æ®é›†
    print("ğŸ“– è¯»å–æ•°æ®é›†...")
    with open(input_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    original_user_count = len(data)
    print(f"âœ… åŸå§‹ç”¨æˆ·æ•°: {original_user_count}")
    
    # ç»Ÿè®¡åŸå§‹æ•°æ®
    total_reviews_before = 0
    user_review_counts = []
    
    for user_data in data:
        reviews = collect_all_reviews(user_data)
        review_count = len(reviews)
        total_reviews_before += review_count
        user_review_counts.append(review_count)
    
    print(f"âœ… åŸå§‹è¯„è®ºæ€»æ•°: {total_reviews_before}")
    print(f"âœ… å¹³å‡æ¯ç”¨æˆ·è¯„è®ºæ•°: {total_reviews_before / original_user_count:.2f}")
    
    # ç»Ÿè®¡è¯„è®ºæ•°åˆ†å¸ƒ
    from collections import Counter
    count_dist = Counter(user_review_counts)
    print(f"\nè¯„è®ºæ•°åˆ†å¸ƒ (å‰10ä¸ª):")
    for count, num_users in sorted(count_dist.items(), reverse=True)[:10]:
        print(f"  {count:3d} æ¡è¯„è®º: {num_users:5d} ä¸ªç”¨æˆ·")
    
    # é‡‡æ ·
    print(f"\nğŸ² å¼€å§‹é‡‡æ · (ä¿ç•™æ¯ä¸ªç”¨æˆ·çš„å {keep_ratio * 100:.1f}% è¯„è®º)...")
    sampled_data = []
    total_reviews_after = 0
    affected_users = 0
    
    for user_idx, user_data in enumerate(data):
        user_id = get_user_id(user_data, user_id_field)
        if user_id is None:
            user_id = f"user_{user_idx}"
        
        # æ”¶é›†æ‰€æœ‰è¯„è®º
        all_reviews = collect_all_reviews(user_data)
        original_review_count = len(all_reviews)
        
        if original_review_count == 0:
            # æ²¡æœ‰è¯„è®ºï¼Œè·³è¿‡
            continue
        
        # æŒ‰æ—¶é—´æˆ³æ’åº
        def get_timestamp(review):
            data_item = review['data_item']
            timestamp_str = data_item.get('timestamp', '1970-01-01')
            return parse_timestamp(timestamp_str)
        
        sorted_reviews = sorted(all_reviews, key=get_timestamp)
        
        # è®¡ç®—ä¿ç•™æ•°é‡
        keep_count = max(1, int(original_review_count * keep_ratio))  # è‡³å°‘ä¿ç•™1æ¡
        kept_reviews = sorted_reviews[-keep_count:]  # ä¿ç•™åNæ¡
        
        if keep_count < original_review_count:
            affected_users += 1
        
        total_reviews_after += len(kept_reviews)
        
        # é‡æ–°æ„å»ºç”¨æˆ·æ•°æ®ç»“æ„
        # éœ€è¦å°†ä¿ç•™çš„è¯„è®ºé‡æ–°åˆ†é…åˆ°åŸæ¥çš„ collection ç»“æ„ä¸­
        new_user_data = {
            'user': user_data.get('user', {}).copy(),
            'task': {
                'description': user_data.get('task', {}).get('description', ''),
                'task_behavior_collections': []
            }
        }
        
        # æŒ‰ collection åˆ†ç»„ä¿ç•™çš„è¯„è®º
        kept_by_collection = defaultdict(list)
        for review in kept_reviews:
            collection_idx = review['collection_idx']
            kept_by_collection[collection_idx].append(review)
        
        # é‡å»º collections
        original_collections = user_data.get('task', {}).get('task_behavior_collections', [])
        for collection_idx, collection in enumerate(original_collections):
            if collection_idx in kept_by_collection:
                # è¿™ä¸ª collection æœ‰ä¿ç•™çš„è¯„è®º
                kept_reviews_for_collection = kept_by_collection[collection_idx]
                # æŒ‰åŸå§‹é¡ºåºæ’åºï¼ˆä¿æŒ data_idxï¼‰
                kept_reviews_for_collection.sort(key=lambda r: r['data_idx'])
                
                new_collection = collection.copy()
                new_collection['data'] = [r['data_item'] for r in kept_reviews_for_collection]
                new_user_data['task']['task_behavior_collections'].append(new_collection)
            # å¦‚æœæ²¡æœ‰ä¿ç•™çš„è¯„è®ºï¼Œè·³è¿‡è¿™ä¸ª collection
        
        sampled_data.append(new_user_data)
    
    # ç»Ÿè®¡
    removed_reviews = total_reviews_before - total_reviews_after
    print(f"âœ… é‡‡æ ·å®Œæˆ")
    print(f"   - ä¿ç•™ç”¨æˆ·æ•°: {len(sampled_data)}")
    print(f"   - ä¿ç•™è¯„è®ºæ•°: {total_reviews_after}")
    print(f"   - ç§»é™¤è¯„è®ºæ•°: {removed_reviews} ({removed_reviews/total_reviews_before*100:.2f}%)")
    print(f"   - å—å½±å“ç”¨æˆ·æ•°: {affected_users} ({affected_users/original_user_count*100:.2f}%)")
    print(f"   - ä¿ç•™æ¯”ä¾‹: {total_reviews_after/total_reviews_before*100:.2f}%")
    
    # ä¿å­˜
    print(f"\nğŸ’¾ ä¿å­˜åˆ°: {output_path}")
    output_path_obj = Path(output_path)
    output_path_obj.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(sampled_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… å®Œæˆï¼")
    print("=" * 80)
    
    return {
        'original_user_count': original_user_count,
        'sampled_user_count': len(sampled_data),
        'original_review_count': total_reviews_before,
        'sampled_review_count': total_reviews_after,
        'removed_reviews': removed_reviews,
        'affected_users': affected_users,
        'keep_ratio': keep_ratio,
    }


def main():
    parser = argparse.ArgumentParser(
        description='å¯¹DMSCæ•°æ®é›†è¿›è¡Œé‡‡æ ·ï¼Œæ¯ä¸ªç”¨æˆ·ä¿ç•™åX%çš„è¯„è®ºï¼ˆæŒ‰æ—¶é—´æˆ³æ’åºï¼‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # ä¿ç•™æ¯ä¸ªç”¨æˆ·çš„å50%è¯„è®º
  python sample_dataset_DMSC.py \\
      /mnt/parallel/GIDigitalTwinBench/RealSelf/DMSC/train.json \\
      /mnt/parallel/GIDigitalTwinBench/RealSelf/DMSC/train_50pct.json \\
      --keep_ratio 0.5
  
  # ä¿ç•™æ¯ä¸ªç”¨æˆ·çš„å30%è¯„è®º
  python sample_dataset_DMSC.py \\
      /mnt/parallel/GIDigitalTwinBench/RealSelf/DMSC/train.json \\
      /mnt/parallel/GIDigitalTwinBench/RealSelf/DMSC/train_30pct.json \\
      --keep_ratio 0.3
  
  # ä¿ç•™æ¯ä¸ªç”¨æˆ·çš„å80%è¯„è®º
  python sample_dataset_DMSC.py \\
      /mnt/parallel/GIDigitalTwinBench/RealSelf/DMSC/train.json \\
      /mnt/parallel/GIDigitalTwinBench/RealSelf/DMSC/train_80pct.json \\
      --keep_ratio 0.8
        """
    )
    
    parser.add_argument('input', type=str, help='è¾“å…¥JSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('output', type=str, help='è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--keep_ratio', type=float, default=0.5,
                        help='ä¿ç•™æ¯”ä¾‹ (0.0-1.0)ï¼Œä¾‹å¦‚ 0.5 è¡¨ç¤ºä¿ç•™å50%% (é»˜è®¤: 0.5)')
    parser.add_argument('--user_id_field', type=str, default='name',
                        help='ç”¨æˆ·IDå­—æ®µå (é»˜è®¤: nameï¼Œä» user.profile.name è·å–)')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(args.input).exists():
        print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return 1
    
    # æ£€æŸ¥ keep_ratio èŒƒå›´
    if not (0.0 < args.keep_ratio <= 1.0):
        print(f"âŒ é”™è¯¯: --keep_ratio å¿…é¡»åœ¨ (0.0, 1.0] èŒƒå›´å†…ï¼Œå½“å‰å€¼: {args.keep_ratio}")
        return 1
    
    # æ‰§è¡Œé‡‡æ ·
    result = sample_dmsc_dataset(
        input_path=args.input,
        output_path=args.output,
        keep_ratio=args.keep_ratio,
        user_id_field=args.user_id_field
    )
    
    if result is None:
        return 1
    
    return 0


if __name__ == '__main__':
    exit(main())
