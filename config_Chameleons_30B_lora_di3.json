{
  "model": {
    "name": "Qwen3-30B-A3B-Instruct-2507",
    "path": "/mnt/parallel/models/Qwen3-30B-A3B-Instruct-2507",
    "hf_model_name": "Qwen/Qwen3-30B-A3B-Instruct-2507",
    "checkpoint_dir": "/mnt/parallel/checkpoints",
    "use_lora": true,
    "lora_config": {
      "r": 32,
      "lora_alpha": 64,
      "lora_dropout": 0.05,
      "target_modules":"all-linear",
      "bias": "none",
      "task_type": "CAUSAL_LM"
    }
  },
  "data": {
    "train_path": "/mnt/parallel/GIDigitalTwinBench/RealSelf/Chameleons/train_di3.json"
  },
  "training": {
    "batch_size": 4,
    "eval_batch_size": 4,
    "gradient_accumulation_steps": 8,
    "learning_rate": 0.0002,
    "weight_decay": 0.01,
    "warmup_steps": 100,
    "max_length": 1024,
    "max_context_turns": 15,
    "logging_steps": 10,
    "save_steps": 200,
    "save_total_limit": 5
  },
  "ablation_configs": {
    "profile_and_history_and_context": {
      "use_profile": true,
      "use_history": true,
      "use_context": true,
      "name": "profile_and_history_and_context"
    },
    "profile_and_history": {
      "use_profile": true,
      "use_history": true,
      "use_context": false,
      "name": "profile_and_history"
    },
    "profile_and_context": {
      "use_profile": true,
      "use_history": false,
      "use_context": true,
      "name": "profile_and_context"
    },
    "history_and_context": {
      "use_profile": false,
      "use_history": true,
      "use_context": true,
      "name": "history_and_context"
    },
    "profile_only": {
      "use_profile": true,
      "use_history": false,
      "use_context": false,
      "name": "profile_only"
    },
    "history_only": {
      "use_profile": false,
      "use_history": true,
      "use_context": false,
      "name": "history_only"
    },
    "context_only": {
      "use_profile": false,
      "use_history": false,
      "use_context": true,
      "name": "context_only"
    }
  }
}